# PDFデータ抽出 LLM比較実験手順書

## 1. 目的

本実験は、不動産賃貸借契約書のPDF文書から、指定されたJSONスキーマに基づき構造化データを抽出するタスクにおいて、複数の大規模言語モデル（LLM）および特化サービスを比較し、**コスト効率**と**データ抽出精度**の観点から最も優れたソリューションを特定することを目的とする。

---

## 2. 予備調査・準備

### 2.1. 比較対象サービスの最終確認と環境構築

以下のサービスを比較対象とし、必要なAPIキー、エンドポイント、および認証情報を事前に取得・設定する。

| サービス名 | 提供元 | 必要な準備/インターフェース | 補足事項 |
| :--- | :--- | :--- | :--- |
| **Gemini Pro 2.5 / Flash 2.5** | Google | APIキー取得 | マルチモーダル入力を使用。 |
| **GPT-4o** | OpenAI | APIキー取得 | マルチモーダル入力を使用。 |
| **Claude 3 Opus / Sonnet** | Anthropic | APIキー取得 | マルチモーダル入力を使用。 |
| **Azure Document Intelligence** | Microsoft Azure | Azureアカウント設定、リソース作成、エンドポイントとキーの取得 | LLMのベンチマークとなる特化型サービス。 |

* **共通環境**: Pythonをベースとし、リクエスト、レスポンス処理、コスト記録を一元管理するための共通スクリプトを整備する。

### 2.2. PDF文書の選定と準備（データセット準備）

* **対象文書**: 不動産賃貸借契約書（文字中心、表形式の項目を含む）を**20種類**以上用意する。
* **前処理**: 公平な比較のため、すべてのPDFを**画像データ（PNG/JPEG）**に変換し、Base64エンコードして入力する形式を標準とする。
* **正解データ（Golden Standard）の作成**: 選定したすべてのPDF文書に対し、目標JSONスキーマに厳密に従った**正しいJSON形式のデータ**を手動で作成し、評価用の絶対的な正解とする。

### 2.3. 目標とするJSONスキーマの定義

不動産賃貸借契約書に対応した、以下の詳細なJSONスキーマを使用する。

> ```json
> {
> 	"metadata": { /*...*/ },
> 	"content": {
> 		"fundermental": { /*...*/ },
> 		"building": { /*...*/ },
> 		"terms": { /*...*/ },
> 		"financials": { /*...*/ },
> 		"additional_facilities": [ /*...*/ ],
> 		"stake_holders": [ /*...*/ ],
> 		"special_terms": [ /*...*/ ]
> 	}
> }
> ```
> *(※詳細はユーザー提供のスキーマを参照し、データ型、必須キー、配列構造を厳密に遵守すること)*

### 2.4. 評価基準の定義（メトリクス）

| 評価指標 | 定義 | 目的 |
| :--- | :--- | :--- |
| **項目正答率** | 正解JSONの総フィールド数に対し、**正しく抽出されたフィールド**の割合。 | 抽出された情報量の正確性を評価。 |
| **F1スコア (要素レベル)** | 各キー・バリューペアを要素とみなし、適合率と再現率からF1スコアを算出。 | 部分的な正解や欠落を含めた総合評価。 |
| **完全一致率** | LLMの出力JSONが正解JSONと**文字列として完全に一致**した割合。 | 形式と内容の厳密な正確性を評価。 |
| **スキーマ準拠率** | 出力JSONが定義されたスキーマを満たしている割合（`jsonschema`で検証）。 | 形式エラーがなく、利用可能かを評価。 |
| **平均コスト/PDF** | 1つのPDFの抽出にかかった平均費用（トークン単価に基づく）。 | 実運用時の経済性を評価。 |
| **平均応答時間** | APIリクエスト送信からレスポンス取得までの平均時間。 | 処理の迅速性を評価。 |

---

## 3. 実験計画

### 3.1. 実験設計とデータセットの割り当て

用意した20種類のPDFを4つのグループに分け、各担当者が以下のLLMを割り当てて抽出を実行する。

| 担当者 | 割り当てLLM | 担当PDF (各5種類) |
| :--- | :--- | :--- |
| A | Gemini Pro 2.5 / Flash 2.5 | PDF 1 - 5 |
| B | GPT-4o | PDF 6 - 10 |
| C | Claude 3 Opus / Sonnet | PDF 11 - 15 |
| D | Azure Document Intelligence | PDF 16 - 20 |

### 3.2. プロンプト戦略

すべてのLLMに対し、JSONスキーマを含めたシステムプロンプト.txtに示したシステムプロンプトを使用し、ユーザプロンプトとして対象のPDFを与える。

---

## 4. 実験実施手順

### 4.1. 各LLMへのAPIリクエスト実行

1.  **PDF画像変換**: 割り当てられたPDFをPNGまたはJPEG形式に変換し、Base64エンコードする。
2.  **API送信**: 変換した画像データと、共通のシステムプロンプト、JSONスキーマを含むユーザープロンプトを、割り当てられたLLMのAPIへ送信する。
3.  **データ記録**: APIリクエスト開始時と、JSON応答を完全に受け取った時点の時刻を記録し、**API応答時間**を算出する。
4.  **トークン記録**: 各APIから返された**入力トークン数**と**出力トークン数**を記録する。

### 4.2. 評価とログの記録

各担当者は、LLMが出力したJSONについて以下の評価を行い、共通のログシートに記録する。

1.  **抽出JSONの保存**: LLMから返されたJSON文字列をそのまま保存する。
2.  **スキーマ準拠チェック**: スキーマ検証ツールを用いてエラーの有無を記録。
3.  **メトリクス算出**: 共通の評価スクリプトを実行し、**項目正答率、F1スコア、完全一致率**を算出・記録する。
4.  **コスト計算**: 記録したトークン数と現在のトークン単価（事前に共有）に基づき、**平均コスト/PDF**を円換算で算出・記録する。
5.  **特記事項**: JSONパースエラー、形式間違い（日付など）、推測データの混入など、分析に有用な情報を手動で追記する。

---

## 5. 結果分析と考察

### 5.1. データ集計と可視化

* すべての実験結果を統合し、**精度（項目正答率、F1スコア）**、**コスト（円/PDF）**、**速度（秒）**の平均値をLLMごとに集計する。
* 主要なメトリクスについて、LLM間の比較を棒グラフや散布図を用いて可視化する。

### 5.2. LLMごとの詳細分析

* **抽出傾向**: 各LLMが、表形式データ（費用項目）と非定型データ（特約事項）のどちらで高い精度を示したか分析する。
* **エラーパターン**: 最も頻繁に発生したエラー（スキーマ違反、形式エラー、誤情報）を特定し、その発生率をLLM間で比較する。
* **特化サービスとの比較**: **Azure Document Intelligence**の結果をベンチマークとして、LLMの汎用的な情報抽出能力が契約書特化のシステムにどれだけ対抗できたかを考察する。

### 5.3. 総合評価と推奨モデルの決定

* **コスト対効果（C/P）**: 「高い精度を維持しつつ、最も低コストで運用できるLLM」を特定する。
* **最終推奨モデルの提示**:
    1.  **精度最優先**のケースで推奨するモデルとその根拠。
    2.  **コスト効率最優先**のケースで推奨するモデルとその根拠。